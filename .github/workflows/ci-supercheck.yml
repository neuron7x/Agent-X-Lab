name: CI Supercheck

on:
  pull_request:
  push:
    branches: [main]
  workflow_dispatch:

permissions:
  checks: read
  contents: read
  pull-requests: read

concurrency:
  group: ci-supercheck-${{ github.ref }}
  cancel-in-progress: true

jobs:
  supercheck:
    name: CI Supercheck
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # v4.1.7
      - name: Build expected check set and poll check-runs API
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_EVENT_NAME: ${{ github.event_name }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_EVENT_PATH: ${{ github.event_path }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import fnmatch
          import json
          import os
          import subprocess
          import sys
          import time
          import traceback
          import urllib.error
          import urllib.request


          def api(url):
              req = urllib.request.Request(
                  url,
                  headers={
                      'Authorization': 'Bearer ' + os.environ['GITHUB_TOKEN'],
                      'Accept': 'application/vnd.github+json',
                      'User-Agent': 'ci-supercheck',
                  },
              )
              backoffs = [2, 4, 8]
              for idx, delay in enumerate(backoffs, start=1):
                  try:
                      with urllib.request.urlopen(req, timeout=30) as resp:
                          return json.loads(resp.read().decode('utf-8'))
                  except urllib.error.HTTPError as e:
                      if e.code in (403, 429):
                          retry_after = e.headers.get('Retry-After')
                          reset_at = e.headers.get('x-ratelimit-reset')
                          wait_seconds = None
                          if retry_after:
                              try:
                                  wait_seconds = max(0, int(retry_after))
                              except ValueError:
                                  wait_seconds = None
                          elif reset_at:
                              try:
                                  wait_seconds = max(0, int(reset_at) - int(time.time()))
                              except ValueError:
                                  wait_seconds = None
                          if wait_seconds is not None:
                              print(f"RATE LIMIT: HTTP {e.code}. Sleeping {wait_seconds}s before retry.")
                              time.sleep(wait_seconds)
                          elif idx < len(backoffs):
                              print(f"HTTP {e.code}: retrying in {delay}s.")
                              time.sleep(delay)
                          else:
                              raise
                      elif idx < len(backoffs):
                          print(f"HTTP {e.code}: retrying in {delay}s.")
                          time.sleep(delay)
                      else:
                          raise
                  except urllib.error.URLError as e:
                      if idx < len(backoffs):
                          print(f"NETWORK ERROR: {e.reason}. Retrying in {delay}s.")
                          time.sleep(delay)
                      else:
                          raise


          def changed_files(event_name, repo, event_path):
              event = json.loads(open(event_path, encoding='utf-8').read())
              if event_name == 'pull_request':
                  pr = event['pull_request']['number']
                  files = []
                  page = 1
                  while True:
                      data = api(f'https://api.github.com/repos/{repo}/pulls/{pr}/files?per_page=100&page={page}')
                      if not data:
                          break
                      files.extend(item['filename'] for item in data)
                      page += 1
                  return sorted(set(files))

              data = subprocess.check_output(['git', 'ls-tree', '-r', '--name-only', 'HEAD'], text=True)
              return sorted(line for line in data.splitlines() if line)


          def is_docs_only(paths):
              allowed = (
                  lambda p: p.startswith('docs/')
                  or p.startswith('build_proof/')
                  or p.endswith('.md')
              )
              return all(allowed(p) for p in paths)


          def any_match(paths, predicates):
              for p in paths:
                  for pred in predicates:
                      if pred(p):
                          return True
              return False


          def required_patterns(paths):
              req = []

              ui_preds = [
                  lambda p: p.startswith('src/'),
                  lambda p: p.startswith('workers/'),
                  lambda p: p.startswith('e2e/'),
                  lambda p: p == 'playwright.config.ts',
                  lambda p: p == 'vite.config.ts',
                  lambda p: p == 'vitest.config.ts',
                  lambda p: p == 'eslint.config.js',
                  lambda p: fnmatch.fnmatch(p, 'tsconfig*.json'),
                  lambda p: fnmatch.fnmatch(p, 'package*.json'),
                  lambda p: p.startswith('scripts/'),
              ]
              if any_match(paths, ui_preds):
                  req.extend([
                      'Lint + Typecheck + Unit Tests + Build',
                      'Worker TypeScript',
                      'Playwright E2E Smoke',
                      'Bundle Size Check',
                      'Lighthouse CI',
                  ])

              prod_preds = [
                  lambda p: p.startswith('engine/'),
                  lambda p: p.startswith('udgs_core/'),
                  lambda p: p.startswith('tools/prod_spec/'),
                  lambda p: p.startswith('artifacts/'),
                  lambda p: p == '.github/workflows/prod-spec-gates.yml',
              ]
              if any_match(paths, prod_preds):
                  req.extend([
                      'Schema Validation (G0/G3)',
                      'Full RRD Gate Check',
                  ])

              wf_preds = [
                  lambda p: p.startswith('.github/workflows/'),
                  lambda p: p.startswith('.github/actions/'),
              ]
              if any_match(paths, wf_preds):
                  req.extend([
                      'Workflow Static Hygiene',
                      'Action Pin Verify',
                      'Workflow Tools + Actionlint',
                  ])

              if not is_docs_only(paths):
                  req.extend([
                      'analyze',
                      'review',
                      'scan',
                  ])

              return sorted(set(req))


          def normalize_check_name(name):
              if ' / ' in name:
                  return name.split(' / ', 1)[1]
              return name


          def write_summary(content, overwrite=False):
              summary_path = os.environ.get('GITHUB_STEP_SUMMARY')
              if not summary_path:
                  return
              start_marker = '<!-- CI_SUPERCHECK:START -->'
              end_marker = '<!-- CI_SUPERCHECK:END -->'
              block = f"{start_marker}\n{content}\n{end_marker}\n"
              try:
                  existing = ''
                  if os.path.exists(summary_path):
                      with open(summary_path, 'r', encoding='utf-8') as f:
                          existing = f.read()
                  start = existing.find(start_marker)
                  end = existing.find(end_marker)
                  if start != -1 and end != -1:
                      end += len(end_marker)
                      if end < len(existing) and existing[end:end + 1] == '\n':
                          end += 1
                      existing = existing[:start] + existing[end:]
                  if overwrite:
                      with open(summary_path, 'w', encoding='utf-8') as f:
                          f.write(existing.rstrip('\n'))
                          if existing.strip():
                              f.write('\n\n')
                          f.write(block)
                  else:
                      with open(summary_path, 'a', encoding='utf-8') as f:
                          f.write(block)
              except Exception as ex:
                  print(f"WARN: Summary write failed: {ex}")


          def poll(repo, sha, required):
              if not required:
                  return 0

              start_time = time.time()
              deadline = start_time + 900
              grace_period = start_time + 60
              summary_path = os.environ.get('GITHUB_STEP_SUMMARY')

              print(f"INTEGRITY AUDIT START: Target SHA {sha[:8]}")
              print(f"EXPECTED GATES: {', '.join(required)}")

              # Initialize outside loop to prevent UnboundLocalError on API network failure
              pending = list(required)

              while time.time() < deadline:
                  try:
                      runs = []
                      page = 1
                      while True:
                          data = api(f'https://api.github.com/repos/{repo}/commits/{sha}/check-runs?per_page=100&page={page}')
                          page_runs = data.get('check_runs', [])
                          if not page_runs:
                              break
                          runs.extend(page_runs)
                          page += 1

                      grouped = {}
                      for r in runs:
                          norm_name = normalize_check_name(r['name'])
                          if norm_name != 'CI Supercheck':
                              grouped.setdefault(norm_name, []).append(r)

                      pending = []
                      failed_blocks = []
                      failed_markdown = []

                      for req in list(required):
                          if req not in grouped:
                              if time.time() > grace_period:
                                  print(f"ADAPTIVE PRUNING: '{req}' skipped by YAML paths. Pruning.")
                                  required.remove(req)
                              else:
                                  pending.append(req)
                              continue

                          req_runs = grouped[req]
                          statuses = [r.get('status') for r in req_runs]
                          conclusions = [r.get('conclusion') for r in req_runs]

                          if any(c in ('failure', 'cancelled', 'timed_out', 'action_required') for c in conclusions):
                              bad_run = next(r for r in req_runs if r.get('conclusion') in ('failure', 'cancelled', 'timed_out', 'action_required'))
                              failed_blocks.append(f"'{req}' terminal state. URL: {bad_run.get('html_url')}")
                              failed_markdown.append(f"| ‚ùå **{req}** | {bad_run.get('conclusion').upper()} | [View Logs]({bad_run.get('html_url')}) |")
                              continue

                          if not all(s == 'completed' for s in statuses):
                              pending.append(req)
                              continue

                          if any(c not in ('success', 'neutral', 'skipped') for c in conclusions):
                              pending.append(req)

                      if failed_blocks:
                          for err in failed_blocks:
                              print(f"BLOCKER: {err}")
                          if summary_path:
                              rows = '\n'.join(failed_markdown)
                              write_summary(
                                  "\n".join([
                                      "### ‚ùå CI Integrity Violation",
                                      f"**Target SHA:** `{sha}`",
                                      "",
                                      "| Gate | Conclusion | Evidence |",
                                      "| :--- | :--- | :--- |",
                                      rows,
                                  ]),
                                  overwrite=True,
                              )
                          return 1

                      missing = [r for r in required if r not in grouped]
                      if not pending and not missing:
                          print("SUCCESS: All active gates verified.")
                          if summary_path:
                              success_rows = []
                              for r in required:
                                  c = grouped[r][0].get('conclusion', 'success').upper()
                                  success_rows.append(f"| **{r}** | ‚úÖ COMPLETED | {c} |")
                              write_summary(
                                  "\n".join([
                                      "### üõ°Ô∏è CI Integrity Report (AD-2026)",
                                      f"**Target SHA:** `{sha}`",
                                      "",
                                      "| Gate | Status | Conclusion |",
                                      "| :--- | :--- | :--- |",
                                      "\n".join(success_rows),
                                  ]),
                                  overwrite=True,
                              )
                          return 0

                      elapsed = int(time.time() - start_time)
                      print(f"HEARTBEAT [{elapsed}s]: {len(required)-len(pending)}/{len(required)} gates closed.")
                      time.sleep(20)

                  except Exception as e:
                      print(f"TRANSIENT ERROR: {str(e)}. Retrying API...")
                      time.sleep(10)

              print(f"TIMEOUT: Gates {pending} failed to close after 15m.")
              if summary_path:
                  write_summary(
                      "\n".join([
                          "### ‚ö†Ô∏è CI Timeout",
                          f"The following gates failed to close within 15 minutes: `{pending}`",
                      ]),
                      overwrite=True,
                  )
              return 1

          repo = os.environ['GITHUB_REPOSITORY']
          sha = os.environ['GITHUB_SHA']
          files = changed_files(os.environ['GITHUB_EVENT_NAME'], repo, os.environ['GITHUB_EVENT_PATH'])
          required = required_patterns(files)
          print('Changed files count:', len(files))
          print('Required checks:', ', '.join(required) if required else 'none')
          if not required:
              print('No required checks for this change-set; PASS')
              write_summary('### ‚ö° Fast-Path Bypass: No functional changes detected. CI Skipped.', overwrite=True)
              sys.exit(0)

          try:
              sys.exit(poll(repo, sha, required))
          except Exception:
              token = os.environ.get('GITHUB_TOKEN', '')
              crash = traceback.format_exc()
              if token:
                  crash = crash.replace(token, '[REDACTED_TOKEN]')
              print('FATAL: Unhandled exception in CI Supercheck poll.')
              print(crash)
              sys.exit(1)
          PY
